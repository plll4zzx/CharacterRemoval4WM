import tiktoken
from transformers import AutoTokenizer

tokenizer_type='bert-base-uncased'
tokenizer = AutoTokenizer.from_pretrained(tokenizer_type)
# tokenizer = tiktoken.get_encoding("cl100k_base")  # GPT-4 çš„ BPE è¯è¡¨
text_l=['language', "lanÉ¡uage", "lanuage","large lanğ uage model"]
for text in text_l:
    token_ids = tokenizer.encode(text, add_special_tokens=False)
    token_list=[tokenizer.decode(id, skip_special_tokens=True) for id in token_ids]
    print(token_ids)  # è¾“å‡º token ID åºåˆ—
    print(token_list)  # è¿˜åŸ token å¯¹åº”çš„æ–‡æœ¬
    print(tokenizer.decode(token_ids, skip_special_tokens=True))
