import json
import logging
from logging import handlers
import random
import numpy as np
from sklearn.metrics import auc
import unicodedata
import matplotlib.pyplot as plt

keyboard_neighbors = {
    'a': 'qs', 'b': 'vn', 'c': 'xv', 'd': 'sf', 'e': 'wr',
    'f': 'dg', 'g': 'fh', 'h': 'gj', 'i': 'uo', 'j': 'hk',
    'k': 'jl', 'l': 'k', 'm': 'n', 'n': 'bm', 'o': 'ip',
    'p': 'o', 'q': 'wa', 'r': 'et', 's': 'ad', 't': 'ry',
    'u': 'iy', 'v': 'cb', 'w': 'qe', 'x': 'zc', 'y': 'tu',
    'z': 'x'
}

def random_keyboard_neighbor(char):
    neighbors = keyboard_neighbors.get(char.lower(), '')
    return random.choice(neighbors) if neighbors else char


unprintable_char=''.join([chr(i) for i in range(1000) if chr(i).isprintable()==False])[0:10]
homos = {
    "A":"Î‘ÐáŽªá—…á´€ê“®ê­ºï¼¡ðŠ ð–½€ð€ð´ð‘¨ð– ð—”ð˜ˆð˜¼ð™°ðš¨ð›¢ðœœð–ðž",
    'B':'Ê™Î’Ð’Ð²á´á¼á—·ê“ï¼¢ðŠ‚ðŠ¡ðŒððµð‘©ð–¡ð—•ð˜‰ð˜½ð™±ðš©ð›£ðœð—ðž‘',
    'C':'Ï¹Ð¡áŸâ„‚â…­âŠ‚â²¤â¸¦ê“šï¼£ð•ð‚ð¶ð‘ªð–¢ð—–ð˜Šð˜¾ð™²ðŸŒ',
    'D':'áŽ á—žá—ªá´…â……â…®ê““ê­°ï¼¤ðƒð·ð‘«ð”»ð–£ð——ð˜‹ð˜¿ð™³',
    'E':'Î•Ð•áŽ¬á´‡â‹¿â´¹ê“°ê­¼ï¼¥ðŠ†ð‘¢¦ð‘¢®ð¸ð”¼ð–¤ð˜Œð™€ð™´ðš¬ð›¦ðœ ðšðž”',
    'F':'Ïœá–´ê“ï¼¦ðŠ‡ðŠ¥ð”¥ð‘¢¢ðˆ“ð…ð¹ð‘­ð–¥ð—™ð˜ð™ð™µðŸŠ',
    'G':'É¢ÔŒÔá€ê“–ê®ï¼§ð†ðºð‘®ð–¦ð—šð˜Žð™‚ð™¶',
    'H':'ÊœÎ—ÐÐ½áŽ»á•¼â²Žê“§ê®‹ï¼¨ð‹ð‡ð»ð‘¯ð–§ð—›ð˜ð™ƒð™·ðš®ð›¨ðœ¢ðœðž–',
    'I':'ÉªÎ™Ð†Ó€Óâ… â²’ï¼©ðˆð¥ð¼ð‘°ð•€ð—¹ð™¡ð™¸ðš•ðš°ð›ªðœ¤',
    'J':'Í¿ÐˆáŽ«á’á´Šê“™êž²ê­»ï¼ªð‰ð½ð‘±ð’¥ð–©ð—ð˜‘ð™…ð™¹',
    'K':'ÎšÐšá¦á›•â„ªâ²”ê“—ï¼«ð”˜ðŠð¾ð‘²ð–ªð—žð˜’ð™†ð™ºðš±ð›«ðœ¥ðŸðž™',
    'L':'ÊŸážá’ªâ³â³‘ê“¡ê®®ï¼¬ð›ð‘ƒð”¦ð‘¢£ð‘¢²ð–¼–ðˆªð‹ð¿ð‘³ð“›ð•ƒð–«ð—Ÿð˜“ð™‡ð™»',
    'M':'ÎœÏºÐœáŽ·á›–â…¯â²˜ê“Ÿï¼­ðŠ°ðŒ‘ðŒð‘€ð‘´ð–¬ð— ð˜”ð™ˆð™¼ðš³ð›­ðœ§ð¡ðž›',
    'N':'É´Îâ„•â²šê“ ï¼®ð”“ðð‘ð‘µð–­ð—¡ð˜•ð™‰ð™½ðš´ð›®ðœ¨ð¢ðžœ',
    'O':'ðŠ’ðŠ«ð„ð“‚ð‘¢µð‘£ ðŽð‘‚ð‘¶ð’ªð“žð–®ð—¢ð˜–ð™Šð™¾ðš¶ð›°ðœªð¤ðžž',
    'P':'Î¡Ð á¢á‘­á´˜á´©â„™â²¢ê“‘ê®²ï¼°ðŠ•ðð‘ƒð‘·ð–¯ð—£ð˜—ð™‹ð™¿ðš¸ð›²ðœ¬ð¦ðž ',
    'Q':'â„šâµ•ï¼±ðð‘„ð‘¸ð’¬ð“ ð–°ð—¤ð˜˜ð™Œðš€',
    'R':'Æ¦Ê€áŽ¡á’á–‡áš±â„ê“£ê­±ê®¢ï¼²ð’´ð–¼µðˆ–ð‘ð‘…ð‘¹ð“¡ð•½ð–±ð—¥ð˜™ð™ðš',
    'S':'Ð…Õá•ášê“¢ï¼³ðŠ–ð ð–¼ºð’ð‘†ð‘ºð’®ð“¢ð”–ð•Šð•¾ð–²ð—¦ð˜šð™Žðš‚',
    'T':'Î¤Ð¢Ñ‚áŽ¢á´›âŠ¤âŸ™â²¦ê“”ê­²ï¼´ðŠ—ðŠ±ðŒ•ð‘¢¼ð–¼Šð“ð‘‡ð‘»ð–³ð—§ð˜›ð™ðšƒðš»ð›µðœ¯ð©ðž£ðŸ¨',
    'U':'Õáˆ€á‘Œâˆªâ‹ƒê“´ï¼µð“Žð‘¢¸ð–½‚ð”ð‘ˆð‘¼ð’°ð“¤ð–´ð—¨ð˜œð™ðš„',
    'V':'Ñ´Ù§Û·á™á¯â…¤â´¸ê“¦ê›Ÿï¼¶ð”ð‘¢ ð–¼ˆðˆð•ð‘‰ð‘½ð–µð—©ð˜ð™‘ðš…',
    'W':'ÔœáŽ³á”ê“ªï¼·ð‘£¦ð–ð‘Šð‘¾ð’²ð–¶ð—ªð˜žð™’ðš†',
    'X':'Î§Ð¥á™­áš·â…©â²¬âµê“«ï¼¸ðŠðŠ´ðŒ—ðŒ¢ð”§ð‘£¬ð—ð‘‹ð‘¿ð–·ð—«ð˜Ÿð™“ðš‡ðš¾ð›¸ðœ²ð¬ðž¦',
    'Y':'Î¥Ï’Ð£Ò®áŽ©â²¨ê“¬ï¼¹ðŠ²ð‘¢¤ð–½ƒð˜ð‘Œð’€ð–¸ð—¬ð˜ ð™”ðšˆðš¼ð›¶ðœ°ðªðž¤',
    'Z':'Î–áƒâ„¤ê“œï¼ºð‹µð‘¢©ð™ð‘ð’ð–¹ð—­ð˜¡ð™•ðš‰ðš­ð›§ðœ¡ð›ðž•',
    "a": "É‘É‘Î±Ð°âºï½ðšð‘Žð’‚ð’¶ð“ªð”žð–ºð—®ð˜¢ð™–ðšŠð›‚ð›¼ðœ¶ð°ðžª",
    "b": "Ð¬Æ„Ð¬áá‘²á–¯ï½‚ð›ð‘ð’ƒð”Ÿð–»ð—¯ð˜£ð™—ðš‹",
    "c": "Ï²Ï²Ñá´„â…½â²¥ê®¯ï½ƒð½ðœð‘ð’„ð’¸ð“¬ð” ð•”ð–ˆð–¼ð—°ð˜¤ð™˜ðšŒ",
    "d": "ÔÔá§á‘¯â…†â…¾ê“’ï½„ðð‘‘ð’…ð’¹ð“­ð–½ð—±ð˜¥ð™™ðš",
    "e": "ÐµÐµÒ½â„®â„¯â…‡ê¬²ï½…ðžð‘’ð’†ð“®ð”¢ð•–ð–Šð–¾ð—²ð˜¦ð™šðšŽ",
    "f": "ðšÏáºêž™ê¬µï½†ðŸð‘“ð’‡ð”£ð•—ð–‹ð–¿ð—³ð˜§ð™›ðšðŸ‹",
    "g": "É¡É¡Öï½‡ð ð‘”ð’ˆð“°ð”¤ð–Œð—€ð—´ð˜¨ð™œðš",
    "h": "Õ°Ò»Õ°á‚â„Žï½ˆð¡ð’‰ð•™ð—ð—µð˜©ð™ðš‘",
    "i": "Ñ–iÄ±ï½‰ð¢ð‘–ð’Šð’¾ð“²ð”¦ð–Žð—‚ð—¶ð˜ªð™žðš’",
    "j": "Ï³Ï³Ñ˜â…‰ï½Šð£ð‘—ð’‹ð’¿ð“³ð”§ð•›ð–ð—ƒð—·ð˜«ð™Ÿðš“",
    "k": "ðš”ð’Œï½‹ð¤ð‘˜ð’Œð—„ð—¸ð˜¬ð™ ",
    "l": "â…¼|Æ–á›â„“â…¼â²’âµê“²ðš•ðžðž˜",
    "m": "ï½â…¿",
    "n": "Õ¸Õ¸Õ¼ï½Žð§ð‘›ð’ð“ƒð“·ð”«ð•Ÿð–“ð—‡ð—»ð˜¯ð™£ðš—",
    "o": "Ð¾Î¿Ð¾ð¬ð“ªð”–ð‘“ð¨ð‘œð’ð–”ð—ˆð—¼ð˜°ð™¤ðš˜ð›ðœŠð„ð¾ðž¸",
    "p": "Ñ€ÏÑ€â´â²£ï½ð©ð‘ð’‘ð–•ð—‰ð—½ð˜±ð™¥ðš™ð›’ð†ðž€ðžº",
    "q": "Ô›Ô›Õ£Õ¦ï½‘ðªð‘žð’’ð“†ð“ºð––ð—Šð—¾ð˜²ð™¦ðšš",
    "r": "â²…Ð³á´¦â²…ê­‡ê­ˆê®ï½’ð«ð‘Ÿð’“ð“‡ð“»ð”¯ð•£ð–—ð—‹ð—¿ð˜³ð™§ðš›",
    "s": "Ñ•Ñ•êœ±ê®ªï½“ð‘ˆð‘£ð¬ð‘ ð’”ð“ˆð“¼ð”°ð•¤ð–˜ð—Œð˜€ð˜´ð™¨ðšœ",
    "t": "ðšð­ð‘¡ð’•ð“‰ð“½ð”±ð•¥ð–™ð—ð˜ð˜µð™©ðš",
    "u": "Õ½Ê‹Ï…Õ½á´œêžŸê­Žê­’ï½•ð“¶ð‘£˜ð®ð‘¢ð’–ð“Šð“¾ð”²ð•¦ð–šð—Žð˜‚ð˜¶ð™ª",
    "v": "ÑµÎ½×˜á´ ",
    "w": "ÔÉ¯Ñ¡ÔÕ¡á´¡ð“Œð”€ð”´ð•¨ð–œð—ð˜„ð˜¸ð™¬ðš ",
    "x": "Ã—Ã—Ñ…â¨¯ð±ð‘¥ð’™ð“ð”ð—‘ð˜…ð˜¹ð™­ðš¡",
    "y": "ÑƒÑƒÒ¯á»¿ï½™ð‘£œð²ð‘¦ð’šð“Žð”‚ð•ªð—’ð˜†ð˜ºð™®ðš¢ð›„ð›¾ðœ¸ð²ðž¬",
    "z": "á´¢á´¢ê®“ï½šð³ð‘§ð’›ð“ð”ƒð—“ð˜‡ð˜»ð™¯",
}
homos_lo = {
    "A":2,
    'B':4,
    'C':2,
    'D':0,
    'E':2,
    'F':1,
    'G':3,
    'H':4,
    'I':6,
    'J':2,
    'K':2,
    'L':1,
    'M':3,
    'N':3,
    'O':0,
    'P':2,
    'Q':2,
    'R':2,
    'S':2,
    'T':3,
    'U':1,
    'V':3,
    'W':1,
    'X':2,
    'Y':4,
    'Z':1,
    "a":6,
    "b": 3,
    "c": 5,
    "d": 2,
    "e": 8,
    "f": 0,
    "g": 5,
    "h": 6,
    "i": 3,
    "j": 4,
    "k": 1,
    "l": 3,
    "m": 0,
    "n": 3,
    "o": 3,
    "p": 4,
    "q": 5,
    "r": 0,
    "s": 3,
    "t": 0,
    "u": 7,
    "v": 0,
    "w": -1,
    "x": 4,
    "y": 4,
    "z": 2,
}
homos_lo1 = {
    "A":2,
    'B':1,
    'C':1,
    'D':8,
    'E':0,
    'F':0,
    'G':1,
    'H':2,
    'I':1,
    'J':0,
    'K':0,
    'L':7,
    'M':2,
    'N':1,
    'O':11,
    'P':1,
    'Q':2,
    'R':10,
    'S':0,
    'T':1,
    'U':0,
    'V':0,
    'W':0,
    'X':0,
    'Y':0,
    'Z':0,
    "a":3,
    "b": 0,
    "c": 2,
    "d": 0,
    "e": 0,
    "f": 5,
    "g": 0,
    "h": 0,
    "i": 0,
    "j": 2,
    "k": 1,
    "l": 2,
    "m": 0,
    "n": 0,
    "o": 0,
    "p": 0,
    "q": 0,
    "r": 1,
    "s": 0,
    "t": 0,
    "u": 2,
    "v": 1,
    "w": 4,
    "x": 2,
    "y": 0,
    "z": 3,
}
homos_lo2 = {
    "A":0,
    'B':0,
    'C':0,
    'D':0,
    'E':0,
    'F':0,
    'G':0,
    'H':0,
    'I':0,
    'J':0,
    'K':0,
    'L':0,
    'M':0,
    'N':0,
    'O':0,
    'P':0,
    'Q':0,
    'R':0,
    'S':0,
    'T':0,
    'U':0,
    'V':0,
    'W':0,
    'X':0,
    'Y':0,
    'Z':0,
    "a":0,
    "b": 0,
    "c": 0,
    "d": 0,
    "e": 0,
    "f": 0,
    "g": 0,
    "h": 0,
    "i": 5,
    "j": 0,
    "k": 0,
    "l": 3,
    "m": 1,
    "n": 0,
    "o": 0,
    "p": 0,
    "q": 0,
    "r": 0,
    "s": 4,
    "t": 0,
    "u": 0,
    "v": 0,
    "w": 0,
    "x": 0,
    "y": 0,
    "z": 0,
}
import homoglyphs as hg
hgc = hg.Homoglyphs(categories=('CYRILLIC', ))
def find_homo(input_char):
    # input_char=input_char.lower()
    if input_char in homos:
        # return homos[input_char][0]
        return homos[input_char][homos_lo1[input_char]]
        # return homos[input_char][homos_lo2[input_char]]
        # return homos[input_char][max(0, homos_lo[input_char]-1)]
    else:
        # random_char = random.choice(unprintable_char)
        return input_char

def normalize_text(s):
    return unicodedata.normalize('NFKC', s)

def homo_back(input_char, style='del'):
    for key in homos:
        if input_char==homos[key][0]:
            if style=='map':
                return key
            elif style=='del':
                return ''
            elif style=='nol':
                return normalize_text(input_char)
    return input_char

def text_homo_back(text, style='del'):
    new_text=''
    for tmp_char in text:
        new_text=new_text+homo_back(tmp_char, style=style)
    return new_text

def to_string(inputs, step_char=' '):
    output_str=''
    for input in inputs:
        if isinstance(input, list) and len(input)>20:
            continue
        if isinstance(input, str):
            output_str+=input
        else:
            output_str+=str(input)
        output_str+=step_char
    return output_str[0:-1]

def load_json(file_path):
    with open(file_path, 'r') as file:
        dict_list=json.load(file)
    return dict_list

def load_jsonl(file_path):
    dict_list=[]
    with open(file_path, 'r') as file:
        for line in file:
            dict_list.append(json.loads(line))
    return dict_list

def save_json(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as file:
        json.dump(data, file, ensure_ascii=False, indent=4)
    # json_data = json.dumps(data)
    # with open(file_path, 'w', encoding='utf-8') as file:
    #     file.write(json_data)


def save_jsonl(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as file:
        for d in data:
            try:
                json.dump(d, file, ensure_ascii=False, indent=4)
            except:
                print('WARING')
                print(d)

def get_advtext_filename(
        attack_name='',
        dataset_name='',
        victim_name='',
        num_examples=0,
        file_type='.json'
    ):

    return '_'.join([
        attack_name, dataset_name.replace('/','_'), victim_name.replace('/','_'), str(num_examples)
    ])+file_type

def truncation(text, tokenizer=None, max_token_num=100, min_num=80):
    if tokenizer is not None:
        text_ids=tokenizer.encode(text)[1:-1]
        if len(text_ids)<min_num:
            return '', 0
        new_text=tokenizer.decode(text_ids[:max_token_num])
        token_num=len(text_ids[:max_token_num])
    else:
        tokens = text.split()
        if len(tokens)<min_num:
            return '', 0
        sub_tokens=tokens[:max_token_num]
        token_num=len(sub_tokens)
        new_text = " ".join(sub_tokens)
    return new_text, token_num

class Logger(object):
    level_relations = {
        'debug':logging.DEBUG,
        'info':logging.INFO,
        'warning':logging.WARNING,
        'error':logging.ERROR,
        'crit':logging.CRITICAL
    }#æ—¥å¿—çº§åˆ«å…³ç³»æ˜ å°„

    def __init__(self,filename,level='info', when='D',backCount=3, screen=True):
        self.logger = logging.getLogger(filename)
        self.logger.handlers.clear()
        # fmt_file='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'
        fmt_file='%(asctime)s - %(levelname)s: %(message)s'
        t_format_str = logging.Formatter(fmt_file)#è®¾ç½®æ—¥å¿—æ ¼å¼

        self.logger.setLevel(self.level_relations.get(level))#è®¾ç½®æ—¥å¿—çº§åˆ«
        th = handlers.TimedRotatingFileHandler(filename=filename,when=when,backupCount=backCount,encoding='utf-8')#å¾€æ–‡ä»¶é‡Œå†™å…¥#æŒ‡å®šé—´éš”æ—¶é—´è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶çš„å¤„ç†å™¨
        #å®žä¾‹åŒ–TimedRotatingFileHandler
        #intervalæ˜¯æ—¶é—´é—´éš”ï¼ŒbackupCountæ˜¯å¤‡ä»½æ–‡ä»¶çš„ä¸ªæ•°ï¼Œå¦‚æžœè¶…è¿‡è¿™ä¸ªä¸ªæ•°ï¼Œå°±ä¼šè‡ªåŠ¨åˆ é™¤ï¼Œwhenæ˜¯é—´éš”çš„æ—¶é—´å•ä½ï¼Œå•ä½æœ‰ä»¥ä¸‹å‡ ç§ï¼š
        # S ç§’
        # M åˆ†
        # H å°æ—¶ã€
        # D å¤©ã€
        # W æ¯æ˜ŸæœŸï¼ˆinterval==0æ—¶ä»£è¡¨æ˜ŸæœŸä¸€ï¼‰
        # midnight æ¯å¤©å‡Œæ™¨
        th.setFormatter(t_format_str)#è®¾ç½®æ–‡ä»¶é‡Œå†™å…¥çš„æ ¼å¼
        self.logger.addHandler(th)
        
        if screen:
            s_fmt_file='%(message)s'
            s_format_str = logging.Formatter(s_fmt_file)#è®¾ç½®æ—¥å¿—æ ¼å¼
            sh = logging.StreamHandler()#å¾€å±å¹•ä¸Šè¾“å‡º
            sh.setFormatter(s_format_str) #è®¾ç½®å±å¹•ä¸Šæ˜¾ç¤ºçš„æ ¼å¼
            sh.addFilter(self._screen_filter)  # Add custom filter to screen handler
            self.logger.addHandler(sh) #æŠŠå¯¹è±¡åŠ åˆ°loggeré‡Œ

    @staticmethod
    def _screen_filter(record):
        return len(record.getMessage()) <= 200

def compute_auc(a, b, num_thresholds=50, fig_path=None):
    """
    Compute AUC by threshold sweeping from scores in list a (positives) and b (negatives).

    Args:
        a (list or array): Scores for positive samples.
        b (list or array): Scores for negative samples.
        num_thresholds (int): Number of thresholds to evaluate.

    Returns:
        float: Computed AUC.
    """
    a = np.array(a)
    b = np.array(b)

    # Combine scores to get global min/max for threshold sweeping
    scores = np.concatenate([a, b])
    thresholds = np.linspace(scores.min(), scores.max(), num_thresholds)

    tpr_list = []
    fpr_list = []

    for thresh in thresholds:
        tp = np.sum(a >= thresh)
        fn = np.sum(a < thresh)
        fp = np.sum(b >= thresh)
        tn = np.sum(b < thresh)

        tpr = tp / (tp + fn + 1e-8)  # True Positive Rate
        fpr = fp / (fp + tn + 1e-8)  # False Positive Rate

        tpr_list.append(tpr)
        fpr_list.append(fpr)

    # Compute AUC using sklearn's auc function (x must be sorted)
    sorted_pairs = sorted(zip(fpr_list, tpr_list))
    fpr_sorted, tpr_sorted = zip(*sorted_pairs)


    if fig_path is not None:
        plt.figure()
        plt.plot(fpr_list, tpr_list, label="Normalized log-log ROC")
        plt.xlabel("log10(FPR)")
        plt.ylabel("Normalized log10(TPR)")
        plt.grid(True)
        plt.legend()
        plt.savefig(fig_path)
    return auc(fpr_sorted, tpr_sorted)

def compute_log_auc(a, b, log_min=1e-5, log_max=1.0, num_thresholds=1000, fig_path=None):
    """
    Compute the normalized log-log AUC and optionally plot the ROC curve in log-log space.

    Parameters:
        a (list or np.ndarray): Scores for positive examples. Higher values indicate positive class.
        b (list or np.ndarray): Scores for negative examples.
        log_fpr_min (float): Minimum value for FPR in log10 space to avoid log(0).
        log_fpr_max (float): Maximum value for FPR in log10 space.
        num_points (int): Number of interpolation points in log space.
        plot (bool): Whether to display the ROC curve plot.

    Returns:
        float: Normalized log-log AUC value.
    """
    
    # Combine and sort scores to determine thresholds
    all_scores = np.sort(np.concatenate([a, b]))
    thresholds = np.linspace(all_scores.min(), all_scores.max(), num_thresholds)

    # Initialize lists to store FPR and TPR
    fpr_list = []
    tpr_list = []

    P = len(a)
    N = len(b)

    for thresh in thresholds:
        tp = np.sum(a >= thresh)
        fp = np.sum(b >= thresh)
        fn = np.sum(a < thresh)
        tn = np.sum(b < thresh)

        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0

        fpr_list.append(fpr)
        tpr_list.append(tpr)

    sorted_pairs = sorted(zip(fpr_list, tpr_list))
    fpr_list, tpr_list = zip(*sorted_pairs)
    fpr_array = np.array(fpr_list)
    tpr_array = np.array(tpr_list)

    # Clip to avoid log(0)
    fpr_clipped = np.clip(fpr_array, log_min, log_max)
    tpr_clipped = np.clip(tpr_array, log_min, log_max)

    # Normalize log10(TPR) to [0, 1]
    log_tpr = tpr_clipped#np.log10(tpr_clipped)/5+1
    log_fpr = np.log10(fpr_clipped)/5+1
    # log_tpr_min = np.log10(1e-5)
    # log_tpr_max = np.log10(1.0)
    # log_tpr_normalized = (log_tpr - log_tpr_min) / (log_tpr_max - log_tpr_min)

    # Compute normalized log-log AUC manually
    log_log_auc_normalized = auc(log_fpr, log_tpr)

    # Plot the normalized log-log ROC curve
    if fig_path is not None:
        plt.figure()
        plt.plot(log_fpr, log_tpr, label="Normalized log-log ROC")
        plt.xlabel("log10(FPR)")
        plt.ylabel("Normalized log10(TPR)")
        plt.title(f"Normalized Log-Log AUC = {log_log_auc_normalized:.4f}")
        plt.grid(True)
        plt.legend()
        plt.savefig(fig_path)

    return log_log_auc_normalized


if __name__=='__main__':
    np.random.seed(0)
    a = np.random.uniform(0.65, 1.0, 1000)  # positive samples
    b = np.random.uniform(0.0, 0.55, 1000)  # negative samples

    auc_v = compute_auc(a,b,num_thresholds=100,fig_path='2.png')
    print(auc_v)
    auc_v = compute_log_auc(a,b,num_thresholds=100,fig_path='1.png')
    print(auc_v)